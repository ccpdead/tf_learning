{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d28a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = glob.glob('/home/jhr/Documents/data/dc_2000/train/*/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69580e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf33b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_image_path[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c2472",
   "metadata": {},
   "source": [
    "用python的切片测试label编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77635382",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/jhr/Documents/data/dc_2000/train/dog/dog.524.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae90a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(p.split('/')[-1].split('.')[0] == 'dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3561e26b",
   "metadata": {},
   "source": [
    "利用切片进行labels编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_label = [int(p.split('/')[-1].split('.')[0] == 'cat')\n",
    "                     for p in train_image_path]\n",
    "\n",
    "train_image_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b7781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_precess_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255  # 归一化\n",
    "    label = tf.reshape(label, [1])\n",
    "    return image, label\n",
    "\n",
    "# tf.image.convert_image_dtype#该函数对于图片是32的会自动做归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71184421",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_image_path, train_image_label))\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "dataset = dataset.map(load_precess_image,\n",
    "                      num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d956281",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb7c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_count = len(train_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据进行batch，shuffle预处理\n",
    "dataset = dataset.shuffle(train_count).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(AUTOTUNE)  # 后台读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     tf.keras.layers.Conv2D(64, (3, 3), input_shape=(\n",
    "#         256, 256, 3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),  # 图像缩小1倍\n",
    "#     tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),  # 缩小\n",
    "#     tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),  # 缩小\n",
    "#     tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),  # 缩小\n",
    "#     tf.keras.layers.Conv2D(1024, (3, 3), activation='relu'),\n",
    "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#     tf.keras.layers.Dense(256, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d00a7c",
   "metadata": {},
   "source": [
    "## 优化模型1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc05407",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(\n",
    "        256, 256, 3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(\n",
    "        256, 256, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),  # 图像缩小1倍\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),  # 缩小\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),  # 缩小\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),  # 缩小\n",
    "    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # 注意，这里没有选用优化函数，softmoix\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e926fe3",
   "metadata": {},
   "source": [
    "## 优化模型2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(\n",
    "        256, 256, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(\n",
    "        256, 256, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d1ea1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52995f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在dataset中取出一个step的数据\n",
    "imgs, labels = next(iter(dataset))\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据进行一个step的计算\n",
    "pred = model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaaa2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([p[0].numpy() for p in tf.cast(pred > 0, tf.int32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135deb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([l[0].numpy() for l in tf.cast(labels > 0, tf.int32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001091b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "ls = tf.keras.losses.BinaryCrossentropy()\n",
    "ls([0., 0., 1., 1.], [1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b084c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "epoch_loss_avg = tf.keras.metrics.Mean('train_loss')  # 计算损失值\n",
    "train_accuracy = tf.keras.metrics.Accuracy('train_acc')  # 计算正确率\n",
    "\n",
    "epoch_loss_avg_test = tf.keras.metrics.Mean('train_loss_test')  # 计算损失值\n",
    "train_accuracy_test = tf.keras.metrics.Accuracy('train_acc_test')  # 计算正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c30fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用损失函数，计算一次的准确率\n",
    "a = train_accuracy(labels, tf.cast(pred > 0, tf.int32))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, images, labels):\n",
    "    with tf.GradientTape() as t:\n",
    "        pred = model(images)\n",
    "        # 模型中没有激活函数，from_logis设置为true，进行内部激活，\n",
    "        # 该函数计算损失值\n",
    "        loss_step = tf.keras.losses.BinaryCrossentropy(\n",
    "            from_logits=True)(labels, pred)\n",
    "    # 计算梯度\n",
    "    grads = t.gradient(loss_step, model.trainable_variables)\n",
    "    # 优化参数\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    epoch_loss_avg(loss_step)\n",
    "    train_accuracy(labels, tf.cast(pred > 0, tf.int32))  # 计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f0ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, images, labels):\n",
    "    pred = model.predict(images)  # 预测模式\n",
    "    loss_step = tf.keras.losses.BinaryCrossentropy(\n",
    "        from_logits=True)(labels, pred)\n",
    "    epoch_loss_avg_test(loss_step)\n",
    "    train_accuracy_test(labels, tf.cast(pred > 0, tf.int32))  # 计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_result = []\n",
    "train_acc_result = []\n",
    "train_loss_result_test = []\n",
    "train_acc_result_test = []\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for imas_, labels_ in dataset:\n",
    "        train_step(model, imas_, labels_)\n",
    "        print(\".\", end='')\n",
    "    print()\n",
    "    train_loss_result.append(epoch_loss_avg.result())\n",
    "    train_acc_result.append(train_accuracy.result())\n",
    "    print(\"epoch:{},loss:{:.3f},acc:{:.3f}\".format(epoch+1, epoch_loss_avg.result(),\n",
    "                                                   train_accuracy.result()))\n",
    "\n",
    "    for imas_, labels_ in dataset:\n",
    "        test_step(model, imas_, labels_)\n",
    "        print(\".\", end='')\n",
    "    print()\n",
    "    train_loss_result_test.append(epoch_loss_avg_test.result())\n",
    "    train_acc_result_test.append(train_accuracy_test.result())\n",
    "    print(\"testing,loss:{:.3f},acc:{:.3f}\".format(epoch_loss_avg_test.result(),\n",
    "                                                  train_accuracy_test.result()))\n",
    "    epoch_loss_avg.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    epoch_loss_avg_test.reset_states()\n",
    "    train_accuracy_test.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418231cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,epoch+2),train_loss_result,label=\"train_loss_result\")\n",
    "plt.plot(range(1,epoch+2),train_acc_result,label=\"train_acc_result\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8c648",
   "metadata": {},
   "source": [
    "# 猫狗数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acb55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a995e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = glob.glob('/home/jhr/Documents/data/dc_2000/train/*/*.jpg')\n",
    "train_image_label = [int(p.split('/')[-1].split('.')[0] == 'cat')\n",
    "                     for p in train_image_path]\n",
    "train_image_label[:5],len(train_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00930941",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path_test = glob.glob('/home/jhr/Documents/data/dc_2000/test/*/*.jpg')\n",
    "train_image_label_test  = [int(p.split('/')[-1].split('.')[0] == 'cat')\n",
    "                     for p in train_image_path_test ]\n",
    "\n",
    "train_image_label_test [:5],len(train_image_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3912be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#图片增强\n",
    "def load_precess_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    # image = tf.image.random_crop(image, [256, 256, 3])  # 随机裁剪\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    # image = tf.image.random_brightness(image, 0.5)\n",
    "    # image = tf.image.random_hue(image,0.5)\n",
    "    # image = tf.image.random_contrast(image, 0, 1)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255  # 归一化\n",
    "    label = tf.reshape(label, [1])\n",
    "    return image, label\n",
    "\n",
    "def load_precess_image_test(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255  # 归一化\n",
    "    label = tf.reshape(label, [1])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a99f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_image_path, train_image_label))\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "dataset = dataset.map(load_precess_image,\n",
    "                      num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_image_path_test, train_image_label_test))\n",
    "dataset_test = dataset_test.map(load_precess_image_test,\n",
    "                      num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ee442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img,label in dataset.take(1):\n",
    "#     plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e039c1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for img_test,label_test in dataset_test.take(1):\n",
    "#     plt.imshow(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95768202",
   "metadata": {},
   "outputs": [],
   "source": [
    "step=32\n",
    "dataset=dataset.shuffle(2000).repeat().batch(step)\n",
    "dataset_test=dataset_test.batch(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64617a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3b13d",
   "metadata": {},
   "source": [
    "## VGG网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf20bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3),input_shape=(256,256,3),padding='same',activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(256,(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(256,(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(256,(1,1),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(512,(1,1),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(512,(1,1),activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())#全连接层 \n",
    "model.add(tf.keras.layers.Dense(4096,activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(4096,activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(1000,activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Conv2D(64,(3,3),input_shape=(256,256,3)))#卷积层\n",
    "# model.add(tf.keras.layers.BatchNormalization())#批标准化层\n",
    "# model.add(tf.keras.layers.Conv2D(64,(3,3)))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#连接层\n",
    "\n",
    "# model.add(tf.keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#连接层\n",
    "\n",
    "# model.add(tf.keras.layers.Conv2D(256,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Conv2D(256,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "# model.add(tf.keras.layers.Conv2D(512,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Conv2D(512,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "# model.add(tf.keras.layers.Conv2D(1024,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "# model.add(tf.keras.layers.Dense(1024,activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f2eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Conv2D(64,(3,3),input_shape=(256,256,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#默认2x2\n",
    "# model.add(tf.keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#默认2x2\n",
    "# model.add(tf.keras.layers.Conv2D(256,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.Conv2D(256,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#默认2x2\n",
    "# model.add(tf.keras.layers.Conv2D(512,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#默认2x2\n",
    "# model.add(tf.keras.layers.Conv2D(512,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#默认2x2\n",
    "# model.add(tf.keras.layers.Conv2D(1024,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.GlobalAveragePooling2D())#全局平均池化\n",
    "# model.add(tf.keras.layers.Dense(1024,activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9854f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e910737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a09e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(dataset,\n",
    "          epochs=100,\n",
    "          steps_per_epoch=2000//step,\n",
    "          validation_data=dataset_test,\n",
    "          validation_steps=1000//step\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe67118",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch,history.history.get('accuracy'),label='acc')\n",
    "plt.plot(history.epoch,history.history.get('val_accuracy'),label='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch,history.history.get('loss'),label='loss')\n",
    "plt.plot(history.epoch,history.history.get('val_loss'),label='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab4df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
