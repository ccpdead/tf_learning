{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e14afd4",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "data_dir='../../data/2_class'\n",
    "data_root=pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data_root.iterdir():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有数据地址\n",
    "all_image_path=list(data_root.glob('*/*'))\n",
    "len(all_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1cfc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_path[:3],all_image_path[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d55ecd",
   "metadata": {},
   "source": [
    "**图片地址**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d382e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_path=[str(path)for path in all_image_path]\n",
    "all_image_path[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_image_path)#乱序\n",
    "all_image_path[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_count=len(all_image_path)\n",
    "image_count"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab55456469e158dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**通过sorted排列列表**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46e9c5ed1c50d555"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ff4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将label返回成列表\n",
    "labels_names=sorted(item.name for item in data_root.glob('*/'))\n",
    "labels_names"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**enumerate方法将可迭代对象转化为元组列表**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8130dce08a36d223"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48edcf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#编码\n",
    "label_to_index=dict((name,index) for index,name in enumerate(labels_names))#enumerate将一个列表转化为索引列表，丛零开始\n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e8386bb81c1d523f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**通过索引对label进行0/1编码**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb97422f0247c222"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过字典，将lake，airplane编码成0和1\n",
    "all_image_label=[label_to_index[pathlib.Path(p).parent.name] for p in all_image_path]\n",
    "all_image_label[:5],all_image_path[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9358ed66",
   "metadata": {},
   "source": [
    "**显示图片**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfef3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_label = dict((v,k) for k,v,in label_to_index.items())\n",
    "index_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8da4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看图像内容\n",
    "for n in range(1):\n",
    "    image_index = random.choice(range(len(all_image_path)))\n",
    "    display.display(display.Image(all_image_path[image_index]))\n",
    "    print(index_to_label[all_image_label[image_index]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e6753",
   "metadata": {},
   "source": [
    "# 单张图片的处理过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=all_image_path[0]\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_raw=tf.io.read_file(img_path)#读取图片\n",
    "img_tensor=tf.image.decode_image(img_raw)#图片解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ee78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor=tf.cast(img_tensor,tf.float32)#转换数据类型\n",
    "img_tensor=img_tensor/255#图片归一化\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_image(path):\n",
    "    img_raw=tf.io.read_file(path)#读取图片\n",
    "    img_tensor=tf.image.decode_jpeg(img_raw,channels=3)#图片解码\n",
    "    img_tensor=tf.image.resize(img_tensor,[256,256])\n",
    "    img_tensor=tf.cast(img_tensor,tf.float32)#转换数据类型\n",
    "    img=img_tensor/255#图片归一化\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b516ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示图片\n",
    "image_path=all_image_path[20]\n",
    "plt.imshow(load_preprocess_image(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69cbe1",
   "metadata": {},
   "source": [
    "# 构造tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds=tf.data.Dataset.from_tensor_slices(all_image_path)#从目录加载数据\n",
    "AUTOTUNE=tf.data.experimental.AUTOTUNE\n",
    "image_dateset=path_ds.map(load_preprocess_image,num_parallel_calls=AUTOTUNE)\n",
    "label_dataset=tf.data.Dataset.from_tensor_slices(tf.cast(all_image_label,tf.int64))#这里加载时，通过cast方法将数据转化为64格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2962b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dateset,label_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in image_dateset.take(1):\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "tf.data.Dataset.zip() 方法可以用於合併兩個數據集，以便可以一起處理它們。\n",
    "例如，如果 dataset1 包含圖像數據，dataset2 包含標籤數據，那麼 tf.data.Dataset.zip(dataset1, dataset2) 會創建一個數據集，\n",
    "其中包含圖像和標籤的元組。然後，這個數據集可以一起用於訓練一個圖像分類器。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f283422a245a47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4458b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.zip((image_dateset,label_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c08862",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count=int(image_count*0.2)\n",
    "train_count=image_count-test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a0d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count,train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建训练数据以及测试数据\n",
    "train_data = dataset.skip(test_count)\n",
    "test_data=dataset.take(test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**tf.data.experimental.shuffle_and_repeat() 方法是一種用於將數據集打亂並重複**\n",
    "apply方法作用是对数据进行处理，将数据转化为另一个数据\n",
    "\n",
    "tf.data.Dataset.prefetch() 方法會在數據集上預取 buffer_size 個數據。\n",
    "這意味著當您從數據集中請求數據時，數據集將已經預取了 buffer_size 個數據。這可以提高數據集的性能，因為它可以減少數據集從磁碟或網絡流中讀取數據的次數。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65144e19b15ff492"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aacdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data=train_dataset.repeat().shuffle(buffer_size=train_count).batch(BATCH_SIZE)\n",
    "train_data = train_data.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=train_count))\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "train_data = train_data.prefetch(buffer_size=AUTOTUNE)#预加载数据\n",
    "\n",
    "test_data=test_data.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5be007",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f61016",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Conv2D(64,(3,3),input_shape=(256,256,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#默认2x2\n",
    "# model.add(tf.keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#默认2x2\n",
    "# model.add(tf.keras.layers.Conv2D(256,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.Conv2D(256,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#默认2x2\n",
    "# model.add(tf.keras.layers.Conv2D(512,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#默认2x2\n",
    "# model.add(tf.keras.layers.Conv2D(512,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D())#默认2x2\n",
    "# model.add(tf.keras.layers.Conv2D(1024,(3,3),activation='relu'))\n",
    "# model.add(tf.keras.layers.GlobalAveragePooling2D())#全局平均池化\n",
    "# model.add(tf.keras.layers.Dense(1024,activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "# # model.add(tf.keras.layers.Dense(2,activation='sigmoid'))\n",
    "# model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf4127",
   "metadata": {},
   "source": [
    "## 增加BN层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38212135",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3),input_shape=(256,256,3)))#卷积层\n",
    "model.add(tf.keras.layers.BatchNormalization())#批标准化层\n",
    "model.add(tf.keras.layers.Activation('relu'))#激活层\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D())#连接层\n",
    "model.add(tf.keras.layers.Conv2D(128,(3,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128,(3,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D())#连接层\n",
    "model.add(tf.keras.layers.Conv2D(256,(3,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(256,(3,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "model.add(tf.keras.layers.Conv2D(1024,(3,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Dense(1024))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e483c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ffd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['acc']\n",
    "# )\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b333172",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=train_count//BATCH_SIZE\n",
    "validation_steps=test_count//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,datetime\n",
    "log_dir = os.path.join(\n",
    "    'logs', datetime.datetime.now().strftime(\"%Y%m%d-%H:%M:%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ecc25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data,\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=test_data,\n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ca412",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch,history.history.get('acc'),label='acc')\n",
    "plt.plot(history.epoch,history.history.get('val_acc'),label='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a1d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
