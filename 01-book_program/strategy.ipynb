{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.024989600Z",
     "start_time": "2023-08-19T04:53:01.476474500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.371849Z",
     "start_time": "2023-08-19T04:53:06.028985900Z"
    }
   },
   "id": "218f2d904ffb1370"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_images = train_images[..., None]  #60000，28，28 --》 60000，28，28，1\n",
    "test_images = test_images[..., None]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.383397700Z",
     "start_time": "2023-08-19T04:53:06.374349100Z"
    }
   },
   "id": "f6afca8dcf879487"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_images = train_images / np.float32(255)\n",
    "test_images = test_images / np.float32(255)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.473888900Z",
     "start_time": "2023-08-19T04:53:06.378871300Z"
    }
   },
   "id": "ec47082f5629f716"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices:1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices:{}'.format(strategy.num_replicas_in_sync))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.557316800Z",
     "start_time": "2023-08-19T04:53:06.486764500Z"
    }
   },
   "id": "7c93497a8e1eb60b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#设置输入管道\n",
    "BUFFER_SIZE = len(train_images)\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "EPOCHS = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.558316400Z",
     "start_time": "2023-08-19T04:53:06.516203800Z"
    }
   },
   "id": "98c92fa558325c4f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#创建数据集，并进行分发\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(\n",
    "    GLOBAL_BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.804769400Z",
     "start_time": "2023-08-19T04:53:06.524154100Z"
    }
   },
   "id": "9de99b4e60282d8d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#创建模型\n",
    "def create_model():\n",
    "    regularizer = tf.keras.regularizers.L2(1e-5)  #正则化器\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3,\n",
    "                               activation='relu',\n",
    "                               kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(64, 3,\n",
    "                               activation='relu',\n",
    "                               kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64,\n",
    "                              activation='relu',\n",
    "                              kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dense(10, kernel_regularizer=regularizer)\n",
    "    ])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.817529900Z",
     "start_time": "2023-08-19T04:53:06.803343800Z"
    }
   },
   "id": "91259435754dc5f0"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#create a checkpoint directory to store the checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.818530800Z",
     "start_time": "2023-08-19T04:53:06.808777700Z"
    }
   },
   "id": "dd8b04e51f23f698"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "with strategy.scope():\n",
    "    # Set reduction to `NONE` so you can do the reduction yourself.\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True,\n",
    "        reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "\n",
    "    #定义计算损失函数\n",
    "    def compute_loss(labels, predictions, model_losses):\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        loss = tf.nn.compute_average_loss(per_example_loss)\n",
    "        if model_losses:\n",
    "            loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.829928200Z",
     "start_time": "2023-08-19T04:53:06.819677900Z"
    }
   },
   "id": "56e144d624d79138"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#定义跟踪损失以及准确度指标，定义三个指标，test_loss,train_acc,test_acc\n",
    "with strategy.scope():\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        name='train_accuracy')\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        name='test_accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.851625800Z",
     "start_time": "2023-08-19T04:53:06.825917300Z"
    }
   },
   "id": "cda968a4ae4f158b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#循环训练\n",
    "# A model, an optimizer, and a checkpoint must be created under `strategy.scope`.\n",
    "with strategy.scope():\n",
    "    #创建模型\n",
    "    model = create_model()\n",
    "    #创建优化函数\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    #创建checkpoint回调函数\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.879799900Z",
     "start_time": "2023-08-19T04:53:06.860149400Z"
    }
   },
   "id": "a2e6118213a31067"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = compute_loss(labels, predictions, model.losses)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def test_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss.update_state(t_loss)\n",
    "    test_accuracy.update_state(labels, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:06.880802300Z",
     "start_time": "2023-08-19T04:53:06.876283200Z"
    }
   },
   "id": "99e8ab3e986f3631"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "# `run` replicates the provided computation and runs it\n",
    "# with the distributed input.\n",
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                           axis=None)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "979a3ce56daf7d92"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5092597603797913, Accuracy: 81.71333312988281, Test Loss: 0.3729873597621918, Test Accuracy: 86.44000244140625\n",
      "Epoch 2, Loss: 0.34039872884750366, Accuracy: 87.66999816894531, Test Loss: 0.32193049788475037, Test Accuracy: 88.37000274658203\n",
      "Epoch 3, Loss: 0.29635900259017944, Accuracy: 89.38833618164062, Test Loss: 0.3093103766441345, Test Accuracy: 89.16000366210938\n",
      "Epoch 4, Loss: 0.2683040201663971, Accuracy: 90.45333099365234, Test Loss: 0.2826783359050751, Test Accuracy: 89.84000396728516\n",
      "Epoch 5, Loss: 0.24595151841640472, Accuracy: 91.22666931152344, Test Loss: 0.28471988439559937, Test Accuracy: 89.45999908447266\n",
      "Epoch 6, Loss: 0.22732500731945038, Accuracy: 91.90666961669922, Test Loss: 0.2745018005371094, Test Accuracy: 89.99000549316406\n",
      "Epoch 7, Loss: 0.21033954620361328, Accuracy: 92.61500549316406, Test Loss: 0.25763633847236633, Test Accuracy: 90.55999755859375\n",
      "Epoch 8, Loss: 0.19666792452335358, Accuracy: 93.08999633789062, Test Loss: 0.25555938482284546, Test Accuracy: 90.43000030517578\n",
      "Epoch 9, Loss: 0.1824449747800827, Accuracy: 93.49500274658203, Test Loss: 0.26523828506469727, Test Accuracy: 90.48999786376953\n",
      "Epoch 10, Loss: 0.1693001091480255, Accuracy: 94.08499908447266, Test Loss: 0.2516801953315735, Test Accuracy: 91.0\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def distributed_test_step(dataset_inputs):\n",
    "    return strategy.run(test_step, args=(dataset_inputs,))\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # TRAIN LOOP\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for x in train_dist_dataset:\n",
    "        total_loss += distributed_train_step(x)#损失计算函数\n",
    "        num_batches += 1\n",
    "    train_loss = total_loss / num_batches\n",
    "\n",
    "    # TEST LOOP\n",
    "    for x in test_dist_dataset:\n",
    "        distributed_test_step(x)\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        checkpoint.save(checkpoint_prefix)\n",
    "\n",
    "    template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \"\n",
    "                \"Test Accuracy: {}\")\n",
    "    print(template.format(epoch + 1, train_loss,\n",
    "                          train_accuracy.result() * 100, test_loss.result(),\n",
    "                          test_accuracy.result() * 100))\n",
    "\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T04:53:06.885334Z"
    }
   },
   "id": "3cb9f7b6dd104200"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:57:46.031957Z",
     "start_time": "2023-08-19T04:57:46.004096600Z"
    }
   },
   "id": "86868027609457d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
